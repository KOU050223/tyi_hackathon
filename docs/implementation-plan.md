# リアルタイム表情連動デジタルお面 実装計画

## Context（背景と目的）

アニメ『ラブライブ！』に登場する「璃奈ちゃんボード」のような、**リアルタイム表情連動デジタルお面**をWeb技術で実装します。

### 解決する課題
- スマートフォン/タブレットをお面として使用し、リアルタイムで表情を認識してドット絵で表現する
- ネイティブアプリではなく、ブラウザだけで完結するWebアプリとして実現
- スマホのリアカメラで至近距離（10-20cm）の顔を認識する技術的課題を解決

### 技術的背景
2026年現在、以下の技術が成熟しており実現可能：
- MediaPipe Face Landmarker: 478個の3Dランドマーク + 52個のBlendshape
- WebGPU: 全主要ブラウザ対応完了、推論を3倍高速化
- Canvas API + requestAnimationFrame: 60fps以上の低遅延レンダリング
- PWA: スマホでのネイティブアプリ相当の体験

## 推奨技術スタック

### コア技術
- **フレームワーク**: Vite 6.x + React 19.x + TypeScript 5.7+
- **顔認識**: MediaPipe Face Landmarker (@mediapipe/tasks-vision ^0.10.18)
- **レンダリング**: Canvas 2D（メイン） + WebGPU（最適化用、オプション）
- **スタイリング**: Tailwind CSS 4.x（CSS変数ベース、設定ファイル不要）
- **状態管理**: Zustand 5.x
- **テスト**: Vitest 2.x + Testing Library
- **PWA**: Vite Plugin PWA + Workbox 7.x

## Phase 1: MVP（最小実装）

現在、このフェーズを実装中です。

### 目標
基本的な顔認識とシンプルなドット絵表示

### タスク
1. ✅ プロジェクトセットアップ
2. ⏳ 必要な依存関係のインストール
3. ⏳ カメラアクセス実装
4. ⏳ MediaPipe統合
5. ⏳ 基本的なドット絵レンダリング
6. ⏳ ユニットテスト作成

## 次のステップ

1. 必要な依存関係をインストール
2. プロジェクト構造のセットアップ
3. カメラアクセス実装から開始
